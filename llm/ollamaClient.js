// llm/ollamaClient.js

async function analyze(text) {
  const res = await fetch('http://localhost:11434/api/chat', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      model: 'llama3',
      format: 'json',        // ðŸ”¥ ESTO ES LA CLAVE
      stream: false,
      messages: [
        {
          role: 'system',
          content: `
Eres un moderador experto de lives musicales.
Responde SOLO con JSON vÃ¡lido.
No expliques nada.
`
        },
        {
          role: 'user',
          content: `
Clasifica este mensaje.

Devuelve exactamente este formato:
{
  "type": "request|vote|rating|normal|spam",
  "song": null | "artista - canciÃ³n"
}

Mensaje:
"${text}"
`
        }
      ]
    })
  });

  const data = await res.json();

  // ðŸ‘‡ ahora SIEMPRE es JSON vÃ¡lido
  return data.message.content;
}

module.exports = { analyze };
